{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb99ab92",
   "metadata": {},
   "source": [
    "# Step 2 TF-IDF\n",
    "TERM FREQUENCY - INVERSE DOCUMENT FREQUENCY\n",
    "- it is not just converting into number\n",
    "- it will weight the importance of each words, giving less importance to stop words \n",
    "- without meaning, no order of word, only weights\n",
    "- will not consider word order or meaning\n",
    "- TF-IDF is a weighted BoW, not a semantic model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ca6a7",
   "metadata": {},
   "source": [
    "## üß† Deep Dive into TF, DF, and IDF\n",
    "\n",
    "Let‚Äôs take an example corpus:\n",
    "\n",
    "```\n",
    "Doc1: \"This is a good book\"\n",
    "Doc2: \"This book is about NLP\"\n",
    "Doc3: \"I love this book\"\n",
    "Doc4: \"This is amazing\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 1Ô∏è‚É£ **Term Frequency (TF)**\n",
    "\n",
    "> Measures how frequently a word occurs in a single document.\n",
    "\n",
    "[\n",
    "TF(t, d) = \\frac{\\text{Number of times term t appears in document d}}{\\text{Total number of terms in document d}}\n",
    "]\n",
    "\n",
    "üëâ Example:\n",
    "\n",
    "* In **Doc1**, ‚Äúthis‚Äù appears **1 time**\n",
    "* Total words = 5\n",
    "  ‚Üí **TF(\"this\", Doc1) = 1/5 = 0.2**\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 2Ô∏è‚É£ **Document Frequency (DF)**\n",
    "\n",
    "> Measures how many documents contain the word at least once.\n",
    "\n",
    "üëâ Example:\n",
    "\n",
    "* ‚Äúthis‚Äù appears in **Doc1, Doc2, Doc3, Doc4** ‚Üí **DF = 4**\n",
    "* ‚ÄúNLP‚Äù appears in **Doc2 only** ‚Üí **DF = 1**\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 3Ô∏è‚É£ **Inverse Document Frequency (IDF)**\n",
    "\n",
    "> Gives higher weight to **rare** words and lower weight to **common** ones.\n",
    "\n",
    "[\n",
    "IDF(t) = \\log\\left(\\frac{N}{DF(t)}\\right)\n",
    "]\n",
    "where `N` = total number of documents.\n",
    "\n",
    "üëâ Example:\n",
    "\n",
    "* N = 4\n",
    "* For ‚Äúthis‚Äù: DF = 4 ‚Üí IDF = log(4/4) = log(1) = **0.0**\n",
    "* For ‚ÄúNLP‚Äù: DF = 1 ‚Üí IDF = log(4/1) = **1.386**\n",
    "\n",
    "So ‚Äúthis‚Äù is **not important** (because it‚Äôs everywhere),\n",
    "but ‚ÄúNLP‚Äù is **important** (because it‚Äôs rare).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 4Ô∏è‚É£ **TF-IDF Weight**\n",
    "\n",
    "[\n",
    "TFIDF(t, d) = TF(t, d) \\times IDF(t)\n",
    "]\n",
    "\n",
    "‚Üí A word‚Äôs final weight depends both on:\n",
    "\n",
    "* **Its frequency** in a document (TF)\n",
    "* **Its rarity** across documents (IDF)\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Intuitive Summary\n",
    "\n",
    "| Word | TF (Doc1)        | DF     | IDF      | TF-IDF Meaning  |\n",
    "| ---- | ---------------- | ------ | -------- | --------------- |\n",
    "| this | High TF, High DF | Common | Low IDF  | Low importance  |\n",
    "| NLP  | Low TF, Low DF   | Rare   | High IDF | High importance |\n",
    "\n",
    "So **TF-IDF = common within document + rare across documents** ‚Üí *most meaningful*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a922741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['active' 'and' 'badminton' 'dancing' 'every' 'gardening' 'happy' 'is'\n",
      " 'keeps' 'love' 'me' 'peaceful' 'play' 'relaxing' 'weekend']\n",
      "TF-IDF Matrix:\n",
      " [[0.         0.39205255 0.4842629  0.4842629  0.         0.\n",
      "  0.         0.         0.         0.61422608 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.30403549 0.         0.         0.         0.47633035\n",
      "  0.         0.47633035 0.         0.         0.         0.47633035\n",
      "  0.         0.47633035 0.        ]\n",
      " [0.         0.         0.41428875 0.         0.52547275 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.52547275 0.         0.52547275]\n",
      " [0.44592216 0.28462634 0.         0.35157015 0.         0.\n",
      "  0.44592216 0.         0.44592216 0.         0.44592216 0.\n",
      "  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"I love badminton and dancing\",\n",
    "    \"Gardening is relaxing and peaceful\",\n",
    "    \"I play badminton every weekend\",\n",
    "    \"Dancing keeps me active and happy\"\n",
    "]\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(corpus)\n",
    "\n",
    "print(\"Feature Names:\", tfidf.get_feature_names_out())\n",
    "print(\"TF-IDF Matrix:\\n\", X_tfidf.toarray())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc744355",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "['active'   'and'   'badminton' 'dancing'  'every'   'gardening' 'happy'     'is',   'keeps'      'love'      'me'      'peaceful'    'play'   'relaxing' 'weekend']\n",
    "\n",
    "sentence1 [[0.         0.39205255 0.4842629  0.4842629  0.         0.         0.         0.         0.         0.61422608 0.         0.           0.         0.           0.        ]\n",
    "sentence2  [0.         0.30403549 0.         0.         0.         0.47633035 0.         0.47633035 0.         0.         0.         0.47633035   0.         0.47633035   0.  ]\n",
    "sentence3  [0.         0.         0.41428875 0.         0.52547275 0.         0.         0.         0.         0.         0.         0.           0.52547275 0.           0.52547275]\n",
    "sentence4  [0.44592216 0.28462634 0.         0.35157015 0.         0.         0.44592216 0.         0.44592216 0.         0.44592216 0.           0.         0.           0.        ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff0404e",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "1. term frequency\n",
    "how many times the word occurs in a document\n",
    "\n",
    "4 documents\n",
    "this is book\n",
    "this is a chair\n",
    "this is a car\n",
    "this is a toy\n",
    "\n",
    "this occurs in 1 time in document 1\n",
    "\n",
    "document1 total words is 3\n",
    "termfreq = 1/3\n",
    "\n",
    "\n",
    "2. document frequency\n",
    "how many times the word occurs across all the documents\n",
    "this word contains in how many documents\n",
    "\n",
    "\n",
    "example\n",
    "this word contains in 4 documents\n",
    "book,car,chair word contains in 1 document\n",
    "\n",
    "\n",
    "\n",
    "3. idf inverse document frequency\n",
    "\n",
    "total no of documents is 4 \n",
    "\n",
    "idf= log(N {total no of documents} / that word contains in how many documents)\n",
    "\n",
    "THIS = log(4/4)  = log(1) = 0 it has no importance , no weight to word\n",
    "book, chair, car = log(4/1) = 1.3 it has some importance weight\n",
    "\n",
    "\n",
    "4. tf-idf \n",
    "\n",
    "In contrast, the TF-IDF for the word \"this\" would be:\n",
    "\n",
    "TF(\"this\") = 1/3 ‚âà 0.33\n",
    "\n",
    "IDF(\"this\") = 0\n",
    "\n",
    "Thus, the TF-IDF for \"this\" is:\n",
    "\n",
    "TF-IDF(\"this\") = 0.33 √ó 0 = 0\n",
    "TF-IDF(\"this\")=0.33√ó0=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f0339",
   "metadata": {},
   "source": [
    "# Inference:\n",
    "- By calculating this we can pass to machine learning models for further processing\n",
    "- eg: text classification or clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ffd3a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
