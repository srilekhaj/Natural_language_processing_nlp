{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0956998",
   "metadata": {},
   "source": [
    "# Loading the paragraph or text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "091b1274",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"NLTK and spaCy are both powerful libraries for Natural Language Processing. They have different approaches to tokenization. NLTK is very customizable, while spaCy is known for speed and efficiency and faster execution.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d632fe60",
   "metadata": {},
   "source": [
    "# Downloading punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51502a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     c:\\Users\\jsril\\anaconda3\\envs\\nlp_env\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt', download_dir=\"c:\\\\Users\\\\jsril\\\\anaconda3\\\\envs\\\\nlp_env\\\\nltk_data\")  # for tokenizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc12137f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\", download_dir=\"C:\\\\nltk_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eebda4",
   "metadata": {},
   "source": [
    "Getting LookupError: \n",
    "**********************************************************************\n",
    "  Resource punkt_tab not found.\n",
    "  Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "  >>> import nltk\n",
    "  >>> nltk.download('punkt_tab')\n",
    "  \n",
    "  For more information see: https://www.nltk.org/data.html\n",
    "\n",
    "  Attempted to load tokenizers/punkt_tab/english/\n",
    "\n",
    "  Searched in:\n",
    "    - 'C:\\\\Users\\\\jsril/nltk_data'\n",
    "    - 'c:\\\\Users\\\\jsril\\\\anaconda3\\\\envs\\\\nlp_env\\\\nltk_data'\n",
    "    - 'c:\\\\Users\\\\jsril\\\\anaconda3\\\\envs\\\\nlp_env\\\\share\\\\nltk_data'\n",
    "    - 'c:\\\\Users\\\\jsril\\\\anaconda3\\\\envs\\\\nlp_env\\\\lib\\\\nltk_data'\n",
    "    - 'C:\\\\Users\\\\jsril\\\\AppData\\\\Roaming\\\\nltk_data'\n",
    "    - 'C:\\\\nltk_data'\n",
    "    - 'D:\\\\nltk_data'\n",
    "    - 'E:\\\\nltk_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f2d4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk punkt unable to find\n",
    "# adding the correct path manaully\n",
    "\n",
    "nltk.data.path.append(\"C:\\\\nltk_data\\\\tokenizers\\\\punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247dd29d",
   "metadata": {},
   "source": [
    "# installing again to remove error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06538de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\jsril\\anaconda3\\envs\\nlp_env\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\jsril\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\jsril\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jsril\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk) (2025.10.23)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jsril\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jsril\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9fa96",
   "metadata": {},
   "source": [
    "LookupError: \n",
    "**********************************************************************\n",
    "  Resource punkt_tab not found.\n",
    "  Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "  >>> import nltk\n",
    "  >>> nltk.download('punkt_tab')\n",
    "  \n",
    "  For more information see: https://www.nltk.org/data.html\n",
    "\n",
    "  Attempted to load tokenizers/punkt_tab/english/\n",
    "\n",
    "  Searched in:\n",
    "    - 'C:\\\\Users\\\\jsril/nltk_data'\n",
    "    - 'c:\\\\Users\\\\jsril\\\\anaconda3\\\\envs\\\\nlp_env\\\\nltk_data'\n",
    "    - 'c:\\\\Users\\\\jsril\\\\anaconda3\\\\envs\\\\nlp_env\\\\share\\\\nltk_data'\n",
    "    - 'c:\\\\Users\\\\jsril\\\\anaconda3\\\\envs\\\\nlp_env\\\\lib\\\\nltk_data'\n",
    "    - 'C:\\\\Users\\\\jsril\\\\AppData\\\\Roaming\\\\nltk_data'\n",
    "    - 'C:\\\\nltk_data'\n",
    "    - 'D:\\\\nltk_data'\n",
    "    - 'E:\\\\nltk_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd6fd9c",
   "metadata": {},
   "source": [
    "# installing punkt_tab to remove lookup error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3082f37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     c:\\Users\\jsril\\anaconda3\\envs\\nlp_env\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06496c70",
   "metadata": {},
   "source": [
    "# Executing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "578fd15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLTK and spaCy are both powerful libraries for Natural Language Processing.', 'They have different approaches to tokenization.', 'NLTK is very customizable, while spaCy is known for speed and efficiency and faster execution.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize , word_tokenize, wordpunct_tokenize\n",
    "\n",
    "sent = sent_tokenize(text)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c98e0a58",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "OUTPUT:\n",
    "['NLTK and spaCy are both powerful libraries for Natural Language Processing.',\n",
    " 'They have different approaches to tokenization.',\n",
    "  'NLTK is very customizable, while spaCy is known for speed and efficiency and faster execution.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4bcfe7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization: ['NLTK and spaCy are both powerful libraries for Natural Language Processing.', 'They have different approaches to tokenization.', 'NLTK is very customizable, while spaCy is known for speed and efficiency and faster execution.']\n",
      "Word Tokenization: ['NLTK', 'and', 'spaCy', 'are', 'both', 'powerful', 'libraries', 'for', 'Natural', 'Language', 'Processing', '.', 'They', 'have', 'different', 'approaches', 'to', 'tokenization', '.', 'NLTK', 'is', 'very', 'customizable', ',', 'while', 'spaCy', 'is', 'known', 'for', 'speed', 'and', 'efficiency', 'and', 'faster', 'execution', '.']\n",
      "Word Punct Tokenization: NLTK and spaCy are both powerful libraries for Natural Language Processing. They have different approaches to tokenization. NLTK is very customizable, while spaCy is known for speed and efficiency and faster execution.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize, wordpunct_tokenize\n",
    "\n",
    "# Sentence Tokenization\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentence Tokenization:\", sentences)\n",
    "\n",
    "# Word Tokenization\n",
    "words = word_tokenize(text)\n",
    "print(\"Word Tokenization:\", words)\n",
    "\n",
    "word_punctuation = wordpunct_tokenize(text)\n",
    "print(\"Word Punct Tokenization:\", text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d7f4579",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Sentence Tokenization: ['NLTK and spaCy are both powerful libraries for Natural Language Processing.', 'They have different approaches to tokenization.', 'NLTK is very customizable, while spaCy is known for speed and efficiency and faster execution.']\n",
    "Word Tokenization: ['NLTK', 'and', 'spaCy', 'are', 'both', 'powerful', 'libraries', 'for', 'Natural', 'Language', 'Processing', '.', 'They', 'have', 'different', 'approaches', 'to', 'tokenization', '.', 'NLTK', 'is', 'very', 'customizable', ',', 'while', 'spaCy', 'is', 'known', 'for', 'speed', 'and', 'efficiency', 'and', 'faster', 'execution', '.']\n",
    "Word Punct Tokenization: NLTK and spaCy are both powerful libraries for Natural Language Processing. They have different approaches to tokenization. NLTK is very customizable, while spaCy is known for speed and efficiency and faster execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5377796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffd47fac",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Number of sentences : 3\n",
    "Number of tokens (words) : 36\n",
    "Observe the differences bettween spacy and NLTK â€” are token counts same?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
