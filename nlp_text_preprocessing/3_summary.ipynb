{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bc5aede",
   "metadata": {},
   "source": [
    "ðŸŒ¸ Hereâ€™s a **visual mini-pipeline** that connects everything weâ€™ve done so far ðŸ‘‡\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§­ **TEXT PREPROCESSING PIPELINE (VISUAL FLOW)**\n",
    "\n",
    "### ðŸ§± **Step 1 â†’ Tokenization**\n",
    "\n",
    "**Goal:** Split text into sentences or words.\n",
    "\n",
    "ðŸ”¹ Example\n",
    "Input:\n",
    "`\"The weather is nice today and the sun is shining.\"`\n",
    "\n",
    "Output (word tokens):\n",
    "`['The', 'weather', 'is', 'nice', 'today', 'and', 'the', 'sun', 'is', 'shining', '.']`\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§± **Step 2 â†’ Stopword Removal**\n",
    "\n",
    "**Goal:** Remove frequent, meaningless words.\n",
    "\n",
    "ðŸ”¹ Example\n",
    "After stopword removal:\n",
    "`['weather', 'nice', 'today', 'sun', 'shining']`\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§± **Step 3 â†’ Stemming & Lemmatization**\n",
    "\n",
    "**Goal:** Reduce words to their **root/base form** to treat similar words as same.\n",
    "\n",
    "ðŸ”¹ Example\n",
    "Before: `['running', 'runs', 'ran']`\n",
    "After stemming â†’ `['run', 'run', 'ran']`\n",
    "After lemmatization â†’ `['run', 'run', 'run']`\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§© **Complete Flow Diagram**\n",
    "\n",
    "```\n",
    "Raw Text\n",
    "   â†“\n",
    "Tokenization\n",
    "   â†“\n",
    "Stopword Removal\n",
    "   â†“\n",
    "Stemming / Lemmatization\n",
    "   â†“\n",
    "Cleaned Text â†’ Used for ML / Deep Learning Models\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”§ **Example End-to-End in One Code (NLTK)**\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "text = \"The weather is nice today and the sun is shining beautifully.\"\n",
    "\n",
    "# 1. Tokenize\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# 2. Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered = [w for w in tokens if w.lower() not in stop_words]\n",
    "\n",
    "# 3. Lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(w) for w in filtered]\n",
    "\n",
    "print(\"Original:\", text)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"After Stopwords:\", filtered)\n",
    "print(\"After Lemmatization:\", lemmatized)\n",
    "```\n",
    "\n",
    "âœ… **Output**\n",
    "\n",
    "```\n",
    "Original: The weather is nice today and the sun is shining beautifully.\n",
    "Tokens: ['The', 'weather', 'is', 'nice', 'today', 'and', 'the', 'sun', 'is', 'shining', 'beautifully', '.']\n",
    "After Stopwords: ['weather', 'nice', 'today', 'sun', 'shining', 'beautifully', '.']\n",
    "After Lemmatization: ['weather', 'nice', 'today', 'sun', 'shining', 'beautifully', '.']\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "So far, youâ€™ve covered:\n",
    "- âœ… Tokenization\n",
    "- âœ… Stopword Removal\n",
    "- âœ… End-to-end preprocessing view\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b798f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
